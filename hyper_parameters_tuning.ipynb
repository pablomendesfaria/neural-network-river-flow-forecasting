{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyper-parameters-tuning.ipynb",
      "provenance": [],
      "mount_file_id": "10oHNt1ggNXpLbMdItdfut1gqCwgla2lO",
      "authorship_tag": "ABX9TyNaKaLuZlHiu4EtuFfnxXGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablomendesfaria/neural-network-river-flow-forecasting/blob/master/hyper_parameters_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmwQIdxdDtTC"
      },
      "source": [
        "# Importações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ8A9vQQlv39"
      },
      "source": [
        "!pip install ray[tune]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRq17yiDDvr"
      },
      "source": [
        "import torch\n",
        "from functools import partial\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/neural-network-river-flow-forecasting/\""
      ],
      "metadata": {
        "id": "5mYU7zb38E2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhzcFDcdHnTU"
      },
      "source": [
        "# Construção da Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cppKODG7vDcA"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, nHLayers=1, l1=100, dropout=0.3):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.nHLayers = nHLayers\n",
        "        self.l1 = l1\n",
        "        self.l2 = int(l1 / 2)\n",
        "        self.drop = dropout\n",
        "\n",
        "        if self.nHLayers == 3:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.rnn_2 = nn.LSTM(self.l1, self.l2)\n",
        "            self.rnn_3 = nn.LSTM(self.l2, self.l2, dropout=self.drop, num_layers=2)\n",
        "            self.linear = nn.Linear(in_features=self.l2, out_features=1)\n",
        "        elif self.nHLayers == 2:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.rnn_2 = nn.LSTM(self.l1, self.l2)\n",
        "            self.linear = nn.Linear(in_features=self.l2, out_features=1)\n",
        "        else:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.linear = nn.Linear(in_features=self.l1, out_features=1)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=self.drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1, 0).unsqueeze(2)\n",
        "\n",
        "        if self.nHLayers == 3:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_2(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_3(x)\n",
        "        elif self.nHLayers == 2:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_2(x)\n",
        "            x = self.dropout(x)\n",
        "        else:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = x[-1]\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xoSQ6zLvNvB"
      },
      "source": [
        "# Carregamento e Tratamento da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oQdBsLyvaZq"
      },
      "source": [
        "def load_data(normalizer):\n",
        "    training_data = pd.read_csv('data/training_data.csv')\n",
        "    training_set = training_data.iloc[:, 1:2].values\n",
        "\n",
        "    return normalizer.fit_transform(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRGQRjUhvfet"
      },
      "source": [
        "def training_sliding_window(training_set):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(7, training_set.shape[0]):\n",
        "        x_train.append(training_set[i-7:i, 0])\n",
        "        y_train.append(training_set[i, 0])\n",
        "\n",
        "    return np.array(x_train), np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyzPTD1wOpF"
      },
      "source": [
        "def test_sliding_window(test_set):\n",
        "    x_test = []\n",
        "    for i in range(7, test_set.shape[0]):\n",
        "        x_test.append(test_set[i-7:i, 0])\n",
        "    return np.array(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWRR5VScwVqV"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lIc9V4MwZ-9"
      },
      "source": [
        "def training(config, checkpoint_dir=None):\n",
        "    lstm = LSTM(config[\"nHLayers\"], config[\"l1\"], config[\"dropout\"])\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            lstm = nn.DataParallel(lstm)\n",
        "    lstm.to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(lstm.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        lstm.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    normalizer = MinMaxScaler(feature_range=(0, 1))\n",
        "    training_set = load_data(normalizer)\n",
        "\n",
        "    x_train, y_train = training_sliding_window(training_set)\n",
        "\n",
        "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    data = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=int(config[\"batch_size\"]), shuffle=True)\n",
        "\n",
        "    for epoch in range(int(config[\"epoch\"])):\n",
        "        running_loss = 0.\n",
        "\n",
        "        for i, data in enumerate(loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = lstm(inputs)\n",
        "            outputs = outputs.flatten()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        running_loss /= len(loader)\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((lstm.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=running_loss)\n",
        "\n",
        "        print(f'ÉPOCA {epoch+1} FINALIZADA: custo {running_loss}')\n",
        "    print(\"Treinamento Finalizado!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJ8R6ZRw1zD"
      },
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NitGMBCEw6Fa"
      },
      "source": [
        "def main(num_samples=5, max_num_epochs=1000, gpus_per_trial=1):\n",
        "    config = {\n",
        "        \"nHLayers\": tune.choice([1, 2, 3]),\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"dropout\": tune.loguniform(0.5, 0.1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16, 32, 64]),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"epoch\": tune.choice(list(range(10, 1001)))\n",
        "    }\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=10,\n",
        "        reduction_factor=2\n",
        "    )\n",
        "\n",
        "    reporter = CLIReporter(metric_columns=[\"loss\", \"training_iteration\"])\n",
        "    \n",
        "    result = tune.run(\n",
        "        partial(training),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter\n",
        "    )\n",
        "    \n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(f\"Best trial config: {best_trial.config}\")\n",
        "    print(\"Best trial final training loss: {}\".format(best_trial.last_result[\"loss\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2E_7HdEw-M9"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main(num_samples=50, max_num_epochs=1000, gpus_per_trial=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}