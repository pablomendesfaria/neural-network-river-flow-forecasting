{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-network.ipynb",
      "provenance": [],
      "mount_file_id": "1_8_uizoRUxFbPcNxqyG3Ge0XXTbx_7qI",
      "authorship_tag": "ABX9TyMImD8df/J7X+2XmI0NUvg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablomendesfaria/neural-network-river-flow-forecasting/blob/master/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmwQIdxdDtTC"
      },
      "source": [
        "# Importações"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRq17yiDDvr"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/neural-network-river-flow-forecasting/\""
      ],
      "metadata": {
        "id": "Hco63dLP4fNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhzcFDcdHnTU"
      },
      "source": [
        "# Construção da Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cppKODG7vDcA"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, nHLayers, l1, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.nHLayers = nHLayers\n",
        "        self.l1 = l1\n",
        "        self.l2 = int(l1 / 2)\n",
        "        self.drop = dropout\n",
        "\n",
        "        if self.nHLayers == 3:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.rnn_2 = nn.LSTM(self.l1, self.l2)\n",
        "            self.rnn_3 = nn.LSTM(self.l2, self.l2, dropout=self.drop, num_layers=2)\n",
        "            self.linear = nn.Linear(in_features=self.l2, out_features=1)\n",
        "        elif self.nHLayers == 2:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.rnn_2 = nn.LSTM(self.l1, self.l2)\n",
        "            self.linear = nn.Linear(in_features=self.l2, out_features=1)\n",
        "        else:\n",
        "            self.rnn_1 = nn.LSTM(input_size=1, hidden_size=self.l1)\n",
        "            self.linear = nn.Linear(in_features=self.l1, out_features=1)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=self.drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(1, 0).unsqueeze(2)\n",
        "\n",
        "        if self.nHLayers == 3:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_2(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_3(x)\n",
        "        elif self.nHLayers == 2:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "            x, _ = self.rnn_2(x)\n",
        "            x = self.dropout(x)\n",
        "        else:\n",
        "            x, _ = self.rnn_1(x)\n",
        "            x = self.dropout(x)\n",
        "\n",
        "        x = x[-1]\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xoSQ6zLvNvB"
      },
      "source": [
        "# Carregamento e Tratamento da Base de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oQdBsLyvaZq"
      },
      "source": [
        "def load_data(normalizer):\n",
        "    training_data = pd.read_csv('data/training_data.csv')\n",
        "    training_set = training_data.iloc[:, 1:2].values\n",
        "\n",
        "    test_data = pd.read_csv('data/test_data.csv')\n",
        "    real_values = test_data.iloc[:, 1:2].values\n",
        "\n",
        "    complete_data = pd.concat((training_data['Vazões'], test_data['Vazões']), axis=0)\n",
        "\n",
        "    test_set = complete_data[len(complete_data) - len(test_data) - 7:].values\n",
        "    test_set = test_set.reshape(-1, 1)\n",
        "\n",
        "    return normalizer.fit_transform(training_set), normalizer.fit_transform(test_set), real_values"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRGQRjUhvfet"
      },
      "source": [
        "def training_sliding_window(training_set):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(7, training_set.shape[0]):\n",
        "        x_train.append(training_set[i-7:i, 0])\n",
        "        y_train.append(training_set[i, 0])\n",
        "\n",
        "    return np.array(x_train), np.array(y_train)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyzPTD1wOpF"
      },
      "source": [
        "def test_sliding_window(test_set):\n",
        "    x_test = []\n",
        "    for i in range(7, test_set.shape[0]):\n",
        "        x_test.append(test_set[i-7:i, 0])\n",
        "    return np.array(x_test)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWRR5VScwVqV"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lIc9V4MwZ-9"
      },
      "source": [
        "def training(lstm, epochs, loader, optimizer, criterion, device):\n",
        "    errors = []\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.\n",
        "\n",
        "        for i, data in enumerate(loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = lstm(inputs)\n",
        "            outputs = outputs.flatten()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        \n",
        "        running_loss /= len(loader)\n",
        "        errors.append(running_loss)\n",
        "        print(f'ÉPOCA {epoch+1} FINALIZADA: custo {running_loss}')\n",
        "    return errors"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcAwSZVGwpDA"
      },
      "source": [
        "# Previsão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fidsq3Mdwqvp"
      },
      "source": [
        "def prediction(lstm, x_test, real_values, errors, normalizer):\n",
        "    lstm.eval()\n",
        "    predictions = lstm.forward(x_test)\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy().reshape(-1, 1)\n",
        "\n",
        "    predictions = normalizer.inverse_transform(predictions)\n",
        "\n",
        "    print(predictions.mean())\n",
        "\n",
        "    print(real_values.mean())\n",
        "\n",
        "    errors = np.array(errors)\n",
        "    plt.figure(figsize=(18, 6))\n",
        "    graph_errors = plt.subplot(1, 2, 1)\n",
        "    graph_errors.set_title('Errors')\n",
        "    plt.plot(errors, '-')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Erro')\n",
        "    graph_test = plt.subplot(1, 2 ,2)\n",
        "    graph_test.set_title('Tests')\n",
        "    plt.plot(real_values, color='red', label='Valor real')\n",
        "    plt.plot(predictions, color='blue', label='Previsões')\n",
        "    plt.xlabel('Dias')\n",
        "    plt.ylabel('Vazão')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZJ8R6ZRw1zD"
      },
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NitGMBCEw6Fa"
      },
      "source": [
        "def main():\n",
        "    normalizer = MinMaxScaler(feature_range=(0, 1))\n",
        "    training_set, test_set, real_values = load_data(normalizer)\n",
        "\n",
        "    x_train, y_train = training_sliding_window(training_set)\n",
        "\n",
        "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "    x_test = test_sliding_window(test_set)\n",
        "\n",
        "    data = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    loader = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True)\n",
        "\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n",
        "\n",
        "    lstm = LSTM(nHLayers=3, l1=256, dropout=0.22848248544632915)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(lstm.parameters(), lr=0.0021918207261538646)\n",
        "    lstm.to(device)\n",
        "\n",
        "    errors = training(lstm, 855, loader, optimizer, criterion, device)\n",
        "\n",
        "    prediction(lstm, x_test, real_values, errors, normalizer)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2E_7HdEw-M9"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}